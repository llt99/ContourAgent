from fastapi import FastAPI, Request, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse
from matplotlib_scalebar.scalebar import ScaleBar
from pykrige.uk import UniversalKriging
from pykrige.ok import OrdinaryKriging
from shapely.geometry import shape as shapely_shape, Polygon as ShapelyPolygon, MultiPolygon, GeometryCollection
from shapely.ops import unary_union
from geojson import FeatureCollection, Feature, Polygon as GeoJSONPolygon
from scipy.ndimage import gaussian_filter
import numpy as np
from itertools import combinations
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import palettable.colorbrewer.diverging
import json
import os
import traceback
from matplotlib.path import Path
from shapely.geometry import shape
import jenkspy
from skimage import measure
import fiona
from shapely.geometry import mapping
from fiona.crs import from_epsg
import zipfile
from skgstat import Variogram
from pyproj import Transformer
from shapely.ops import transform
import base64

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"]
)

def load_basin_union(path):
    if not os.path.exists(path):
        print(f"âš ï¸ æœªæ‰¾åˆ° {path}ï¼Œè·³è¿‡è£å‰ª")
        return None
    with open(path, "r", encoding="utf-8") as f:
        geojson_data = json.load(f)
    geoms = [shapely_shape(feat["geometry"]) for feat in geojson_data["features"]]
    return unary_union(geoms)

basin_union = load_basin_union("scBasin.geojson")

def extract_polygons(geom):
    if geom.is_empty:
        return []
    elif geom.geom_type == 'Polygon':
        return [geom]
    elif geom.geom_type == 'MultiPolygon':
        return list(geom.geoms)
    elif geom.geom_type == 'GeometryCollection':
        return [g for g in geom.geoms if g.geom_type in ['Polygon', 'MultiPolygon']]
    return []

# è£å‰ª
def mask_outside_boundary(grid_x, grid_y, z, boundary_geom):
    if boundary_geom is None:
        return z

    paths = []
    for poly in extract_polygons(boundary_geom):
        coords = np.array(poly.exterior.coords)
        if len(coords) >= 3:
            paths.append(Path(coords))

    points = np.vstack((grid_x.ravel(), grid_y.ravel())).T
    mask = np.zeros(len(points), dtype=bool)
    for path in paths:
        mask |= path.contains_points(points)

    mask = mask.reshape(z.shape)
    z[~mask] = np.nan
    return z

def save_features_to_shapefile(features, shp_path):
    schema = {
        'geometry': 'Polygon',
        'properties': {
            'value': 'float',
            'min_value': 'float',  # âœ… æ”¹æˆå’Œ props ä¸€è‡´
            'max_value': 'float'
        }
    }

    with fiona.open(shp_path, 'w',
                    driver='ESRI Shapefile',
                    crs=from_epsg(4326),
                    schema=schema,
                    encoding='utf-8') as sink:
        for feat in features:
            geom = shape(feat.geometry)
            props = {
                'value': feat.properties['value'],
                'min_value': feat.properties['min_value'],
                'max_value': feat.properties['max_value']
            }
            sink.write({
                'geometry': mapping(geom),
                'properties': props
            })

def zip_shapefile(shp_path):
    base = os.path.splitext(shp_path)[0]
    exts = ['.shp', '.shx', '.dbf', '.prj', '.cpg']
    files = []
    for ext in exts:
        f = base + ext
        if os.path.exists(f) and os.path.getsize(f) > 0:
            files.append(f)
        else:
            print(f"âš ï¸ æ–‡ä»¶ç¼ºå¤±æˆ–ä¸ºç©º: {f}")

    if not files:
        raise RuntimeError("æ²¡æœ‰æœ‰æ•ˆçš„ shapefile æ–‡ä»¶å¯å‹ç¼©")

    zip_path = base + '.zip'
    with zipfile.ZipFile(zip_path, 'w', compression=zipfile.ZIP_DEFLATED) as zipf:
        for f in files:
            print(f"æ·»åŠ åˆ°zip: {f}")
            zipf.write(f, arcname=os.path.basename(f))
    print(f"âœ… å‹ç¼©æ–‡ä»¶ç”Ÿæˆ: {zip_path}")
    return zip_path

# äº¤å‰éªŒè¯
def cross_validation_uk(x, y, values, variogram_model, drift_terms):
    n = len(values)
    residuals = []

    for i in range(n):
        x_train = np.delete(x, i)
        y_train = np.delete(y, i)
        val_train = np.delete(values, i)

        x_val = x[i]
        y_val = y[i]
        true_val = values[i]

        uk = UniversalKriging(
            x_train, y_train, val_train,
            variogram_model=variogram_model,
            drift_terms=drift_terms,
            verbose=False,
            enable_plotting=False
        )
        pred, ss = uk.execute("points", np.array([x_val]), np.array([y_val]))
        pred_val = pred[0]
        residuals.append(true_val - pred_val)

    residuals = np.array(residuals)
    RSS = np.sum(residuals ** 2)
    TSS = np.sum((values - np.mean(values)) ** 2)
    R2 = 1 - RSS / TSS if TSS != 0 else float('nan')
    return RSS, R2

# åŠå˜å¼‚å‡½æ•°å›¾åƒ
def generate_variogram_plot(V, kriging_model, title_suffix=""):
    import io
    import matplotlib.pyplot as plt
    import base64
    import numpy as np
    from matplotlib import rcParams

    rcParams['font.sans-serif'] = ['SimSun']  # ä¸­æ–‡å­—ä½“
    rcParams['axes.unicode_minus'] = False  # è´Ÿå·æ­£å¸¸æ˜¾ç¤º

    exp_lags = V.bins
    exp_gamma = V.experimental
    fig, ax = plt.subplots(figsize=(6, 4), dpi=100)

    ax.scatter(exp_lags, exp_gamma, color='blue', label='å®éªŒç‚¹')

    x_model = np.linspace(min(exp_lags), max(exp_lags), 100)
    y_model = V.fitted_model(x_model)
    ax.plot(x_model, y_model, color='red', label=f'æ‹Ÿåˆæ¨¡å‹: {kriging_model}')

    ax.set_title(f'åŠå˜å¼‚å‡½æ•°å›¾ {title_suffix}')
    ax.set_xlabel('è·ç¦» (m)')
    ax.set_ylabel('åŠå˜å¼‚å€¼ Î³(h)')
    ax.legend()
    ax.grid(True)
    plt.tight_layout()

    img_buf = io.BytesIO()
    plt.savefig(img_buf, format='png')
    plt.close(fig)
    img_buf.seek(0)
    img_base64 = base64.b64encode(img_buf.read()).decode("utf-8")
    return f"data:image/png;base64,{img_base64}"


def spherical_model(h, nugget, partial_sill, range_):
    h = np.asarray(h)
    y = np.piecewise(
        h,
        [h <= range_, h > range_],
        [
            lambda x: nugget + partial_sill * (1.5 * (x / range_) - 0.5 * (x / range_) ** 3),
            lambda x: nugget + partial_sill,
        ]
    )
    return y

def exponential_model(h, nugget, partial_sill, range_):
    h = np.asarray(h)
    return nugget + partial_sill * (1 - np.exp(-h / range_))

def gaussian_model(h, nugget, partial_sill, range_):
    h = np.asarray(h)
    return nugget + partial_sill * (1 - np.exp(-(h / range_) ** 2))

def linear_model(h, nugget, slope, _=None):
    h = np.asarray(h)
    return nugget + slope * h

def get_model_function(model):
    return {
        'spherical': spherical_model,
        'exponential': exponential_model,
        'gaussian': gaussian_model,
        'linear': linear_model,
    }.get(model)

def optimize_single_model(model_name, coords, values):
    V = Variogram(coords, values, model=model_name, normalize=False)
    print("æ‹Ÿåˆå‰å‚æ•°ï¼š", V.parameters)

    V.fit(method='trf')
    print("æ‹Ÿåˆåå‚æ•°ï¼š", V.parameters)

    sill, range_, nugget = V.parameters
    partial_sill = sill - nugget
    nugget_ratio = nugget / sill if sill != 0 else 0
    exp_lags = V.bins
    exp_gamma = V.experimental
    fit_gamma = V.fitted_model(exp_lags)

    rss = np.sum((exp_gamma - fit_gamma) ** 2)
    r2 = 1 - rss / np.sum((exp_gamma - np.mean(exp_gamma)) ** 2)

    return {
        "model": model_name,
        "nugget": nugget,
        "sill": sill,
        "partial_sill": partial_sill,
        "nugget_ratio": nugget_ratio,
        "range": range_,
        "rss": rss,
        "r2": r2,
        "exp_lags": exp_lags,
        "exp_gamma": exp_gamma,
        "fit_gamma": fit_gamma
    }

# ç”ŸæˆåŠå˜å¼‚å‡½æ•°å›¾åƒ
def generate_variogram_plot_from_data(h, gamma, fit_vals, model, title_suffix=""):
    import io
    import matplotlib.pyplot as plt
    import base64

    fig, ax = plt.subplots(figsize=(6, 4), dpi=100)
    ax.scatter(h, gamma, color='blue', label='å®éªŒç‚¹')
    ax.plot(h, fit_vals, color='red', label=f'æ‹Ÿåˆæ¨¡å‹: {model}')
    ax.set_title(f'åŠå˜å¼‚å‡½æ•°å›¾ {title_suffix}')
    ax.set_xlabel('è·ç¦» (m)')
    ax.set_ylabel('åŠå˜å¼‚å€¼ Î³(h)')
    ax.legend()
    ax.grid(True)
    plt.tight_layout()

    img_buf = io.BytesIO()
    plt.savefig(img_buf, format='png')
    plt.close(fig)
    img_buf.seek(0)
    return f"data:image/png;base64,{base64.b64encode(img_buf.read()).decode('utf-8')}"

# çŸ©é˜µåˆ†è§£æ±‚é€†çŸ©é˜µï¼Œç„¶ååˆ©ç”¨é€†çŸ©é˜µå¯¹è§’å…ƒç´ å¿«é€Ÿç®—ç•™ä¸€äº¤å‰éªŒè¯
def compute_covariance_matrix_ok(x, y, sill, nugget, range_, variogram_model):
    coords = np.column_stack((x, y))
    n = len(coords)

    # ===== åŠå˜å¼‚å‡½æ•°æ¨¡å‹å®šä¹‰ =====
    def spherical_model(h, nugget, psill, range_):
        h = np.minimum(h, range_)
        return nugget + psill * (1.5 * (h / range_) - 0.5 * (h / range_) ** 3)

    def exponential_model(h, nugget, psill, range_):
        return nugget + psill * (1 - np.exp(-h / range_))

    def gaussian_model(h, nugget, psill, range_):
        return nugget + psill * (1 - np.exp(-(h / range_)**2))

    def linear_model(h, nugget, slope, _=None):
        return nugget + slope * h

    model_funcs = {
        "spherical": spherical_model,
        "exponential": exponential_model,
        "gaussian": gaussian_model,
        "linear": linear_model
    }

    model_func = model_funcs.get(variogram_model)
    if model_func is None:
        raise ValueError(f"ä¸æ”¯æŒçš„åŠå˜å¼‚å‡½æ•°æ¨¡å‹: {variogram_model}")

    # ===== è®¡ç®—è·ç¦»çŸ©é˜µï¼ˆçŸ¢é‡åŒ–ï¼‰ =====
    dx = coords[:, np.newaxis, 0] - coords[np.newaxis, :, 0]
    dy = coords[:, np.newaxis, 1] - coords[np.newaxis, :, 1]
    h = np.sqrt(dx**2 + dy**2)  # è·ç¦»çŸ©é˜µ h(i,j)

    partial_sill = sill - nugget
    gamma = model_func(h, nugget, partial_sill, range_)
    K = sill - gamma

    # æ•°å€¼ç¨³å®šï¼šåŠ å…¥å¾®å°æ­£åˆ™é¡¹ï¼ˆé˜²æ­¢ç—…æ€çŸ©é˜µï¼‰
    K += np.eye(n) * 1e-10

    return K

# åˆ©ç”¨åæ–¹å·®çŸ©é˜µé€†çŸ©é˜µè®¡ç®—OKç•™ä¸€äº¤å‰éªŒè¯æ®‹å·®ï¼Œè¿”å›RSSå’ŒR2
def loo_cross_validation_ok(x, y, values, sill, nugget, range_, variogram_model,
                            auto_optimize_nugget=False,
                            nugget_ratios=np.linspace(0.01, 0.5, 30),
                            target_krmse=1.0,
                            tol=0.01):
    """
    å¦‚æœ auto_optimize_nugget=Trueï¼Œåˆ™è‡ªåŠ¨è°ƒæ•´ nuggetï¼ˆä½œä¸º sill çš„æ¯”ä¾‹ï¼‰
    ä½¿å¾— KRMSE è¶‹è¿‘ target_krmseï¼Œå¦åˆ™ç›´æ¥ç”¨ä¼ å…¥çš„ nuggetè®¡ç®—ã€‚

    è¿”å›ï¼šRSS, R2, KRME, KRMSE, ä»¥åŠæœ€ä½³ nuggetï¼ˆå½“ä¼˜åŒ–æ—¶ï¼‰
    """
    if not auto_optimize_nugget:
        # ç›´æ¥è®¡ç®—ï¼Œè¿”å›å›ºå®š nugget
        K = compute_covariance_matrix_ok(x, y, sill, nugget, range_, variogram_model)
        try:
            K_inv = np.linalg.inv(K)
        except np.linalg.LinAlgError:
            raise RuntimeError("åæ–¹å·®çŸ©é˜µä¸å¯é€†ï¼Œæ— æ³•åšäº¤å‰éªŒè¯")

        diag = np.diag(K_inv)
        if np.any(np.abs(diag) < 1e-10):
            raise RuntimeError(f"Kâ»Â¹ å¯¹è§’å…ƒç´ è¿‡å°ï¼Œæœ€å°å€¼: {np.min(np.abs(diag)):.2e}")

        K_inv_z = K_inv @ values
        residuals = K_inv_z / diag
        preds = values - residuals

        RSS = np.sum(residuals ** 2)
        TSS = np.sum((values - np.mean(values)) ** 2)
        R2 = 1 - RSS / TSS if TSS != 0 else float('nan')

        std_y = np.std(values)
        krme = np.mean(preds - values)
        krmse = np.mean(((preds - values) / std_y) ** 2)

        # mean_y = np.mean(values)
        # krme = np.mean(preds - values) / mean_y
        # krmse = np.sqrt(np.mean((preds - values) ** 2)) / mean_y

        return RSS, R2, krme, krmse, nugget

    else:
        best_nugget = None
        best_krmse = None
        best_rss = None
        best_r2 = None
        best_krme = None
        best_diff = float("inf")

        for ratio in nugget_ratios:
            nugget_try = ratio * sill
            try:
                K = compute_covariance_matrix_ok(x, y, sill, nugget_try, range_, variogram_model)
                print(f"å°è¯• nugget_ratio={ratio:.3f}, nugget={nugget_try:.4f}, "
                      f"K matrix stats: min={K.min():.4f}, max={K.max():.4f}, mean={K.mean():.4f}")

                K_inv = np.linalg.inv(K)
                diag = np.diag(K_inv)
                if np.any(np.abs(diag) < 1e-10):
                    continue
                K_inv_z = K_inv @ values
                residuals = K_inv_z / diag
                preds = values - residuals
                RSS = np.sum(residuals ** 2)
                TSS = np.sum((values - np.mean(values)) ** 2)
                R2 = 1 - RSS / TSS if TSS != 0 else float('nan')
                # mean_y = np.mean(values)
                # krme = np.mean(preds - values) / mean_y
                # krmse = np.sqrt(np.mean((preds - values) ** 2)) / mean_y

                std_y = np.std(values)
                krme = np.mean(preds - values)
                krmse = np.mean(((preds - values) / std_y) ** 2)


            except Exception:
                continue

            diff = abs(krmse - target_krmse)
            print(f"å°è¯• nugget_ratio={ratio:.3f}, nugget={nugget_try:.4f}, KRMSE={krmse:.4f}, å·®å€¼={diff:.4f}")

            if diff < best_diff:
                best_diff = diff
                best_nugget = nugget_try
                best_krmse = krmse
                best_rss = RSS
                best_r2 = R2
                best_krme = krme

            if diff <= tol:
                print("è¾¾åˆ°å®¹å¿åº¦ï¼Œåœæ­¢æœç´¢")
                break

        if best_nugget is None:
            raise RuntimeError("è‡ªåŠ¨ä¼˜åŒ–æœªæ‰¾åˆ°åˆé€‚çš„ nugget")

        return best_rss, best_r2, best_krme, best_krmse, best_nugget

# K-fold äº¤å‰éªŒè¯
def kfold_uk_cross_validation(lons, lats, values, model, drift_terms, n_splits=5):
    from sklearn.model_selection import KFold
    y_true, y_pred = [], []

    coords = np.column_stack((lons, lats))
    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)

    for train_idx, test_idx in kf.split(coords):
        train_coords = coords[train_idx]
        train_values = values[train_idx]
        test_coords = coords[test_idx]
        test_values = values[test_idx]

        # æ‹†åˆ†
        lon_train, lat_train = train_coords[:, 0], train_coords[:, 1]
        lon_test, lat_test = test_coords[:, 0], test_coords[:, 1]

        # æ¨¡å‹
        uk = UniversalKriging(
            lon_train, lat_train, train_values,
            variogram_model=model,
            drift_terms=drift_terms,
            verbose=False,
            enable_plotting=False
        )
        pred, _ = uk.execute("points", lon_test, lat_test)

        y_true.extend(test_values)
        y_pred.extend(pred)

    y_true = np.array(y_true)
    y_pred = np.array(y_pred)
    RSS = np.sum((y_pred - y_true) ** 2)
    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)
    R2 = 1 - RSS / ss_tot if ss_tot != 0 else float("nan")
    # krme = np.mean(y_pred - y_true) / np.mean(y_true)
    # krmse = np.sqrt(np.mean((y_pred - y_true) ** 2)) / np.mean(y_true)

    krme = np.mean(y_pred - y_true)  # æ–°å…¬å¼ (3)
    std_y = np.std(y_true)
    krmse = np.mean(((y_pred - y_true) ** 2) / (std_y ** 2))

    print(f"RSS: {RSS:.2f}")
    print(f"RÂ²: {R2:.4f}")
    print(f"KRME: {krme:.4f}")
    print(f"KRMSE: {krmse:.4f}")

    return RSS, R2, krme, krmse


def dms_formatter(x, pos=None, is_lat=False):
    # å°†åº¦æ•°xæ ¼å¼åŒ–æˆ åº¦Â°åˆ†'ç§’'' + E/Næˆ–W/Sæ–¹å‘,ä¾‹å¦‚ï¼š100Â°40â€²0â€³ E æˆ– 30Â°40â€²0â€³ N

    deg = int(x)
    min_float = abs((x - deg) * 60)
    minute = int(min_float)
    second = int(round((min_float - minute) * 60))

    # ä¿®æ­£ç§’åˆ†è¿›ä½
    if second == 60:
        second = 0
        minute += 1
    if minute == 60:
        minute = 0
        deg += 1

    # æ–¹å‘åˆ¤æ–­
    if is_lat:
        direction = 'N' if x >= 0 else 'S'
    else:
        direction = 'E' if x >= 0 else 'W'

    deg_abs = abs(deg)
    return f"{deg_abs}Â°{minute}â€² {direction}"

def draw_north_arrow(ax, x=0.95, y=0.85, size=0.08):

    # åœ¨ ax å›¾çš„åæ ‡è½´æ¯”ä¾‹ä½ç½® (x, y) ç”»ä¸€ä¸ªåŒ—ç®­å¤´ï¼ˆé»˜è®¤å³ä¸Šè§’åä¸‹ï¼‰
    ax.annotate('N',
                xy=(x, y), xytext=(x, y - size),
                arrowprops=dict(facecolor='black', width=5, headwidth=15),
                ha='center', va='center', fontsize=14,
                xycoords=ax.transAxes)

def save_kriging_contour_plot(
    grid_x, grid_y, z, contour_levels,
    sample_points = None,
    filename="kriging_contour_map.png", output_dir=".\output", dpi=300):
    """
    ç»˜åˆ¶å…‹é‡Œé‡‘æ’å€¼ç­‰å€¼å›¾å¹¶ä¿å­˜ä¸º PNG æ–‡ä»¶ï¼Œå«è‰²å¸¦ã€åº¦åˆ†ç§’åæ ‡ã€æ¯”ä¾‹å°ºã€æŒ‡å—é’ˆä¸è¾¹ç•Œæ¡†ã€‚

    å‚æ•°:
    - grid_x, grid_y: ç½‘æ ¼åæ ‡ï¼ˆnp.meshgridï¼‰
    - z: æ’å€¼ç»“æœäºŒç»´æ•°ç»„
    - contour_levels: ç­‰å€¼çº¿åˆ†çº§
    - basin_boundary: å¤šè¾¹å½¢è¾¹ç•Œï¼ˆShapely Polygon æˆ– MultiPolygonï¼‰
    - filename: è¾“å‡ºæ–‡ä»¶å
    - output_dir: ä¿å­˜ç›®å½•
    - dpi: å›¾åƒåˆ†è¾¨ç‡
    """
    import os
    import matplotlib.pyplot as plt
    from matplotlib.ticker import FuncFormatter

    try:
        os.makedirs(output_dir, exist_ok=True)
        fig, ax = plt.subplots(figsize=(8, 6), dpi=dpi)

        # æ’å€¼ç­‰å€¼å›¾
        cs = ax.contourf(grid_x, grid_y, z, levels=contour_levels, cmap=palettable.colorbrewer.diverging.RdYlBu_11_r.mpl_colormap)
        cbar = fig.colorbar(cs, ax=ax, orientation="vertical", shrink=0.4, pad=0.03)
        cbar.set_label("åœ°å±‚åšåº¦(m)", fontsize=12)

        # ç»˜åˆ¶åŸå§‹é’»äº•ç‚¹ï¼ˆæ”¯æŒ list[dict] æˆ– list[tuple] æ ¼å¼ï¼‰
        if sample_points:
            try:
                # å¦‚æœæ˜¯ dictï¼Œåˆ™æå–åæ ‡å­—æ®µ
                if isinstance(sample_points[0], dict):
                    if "lng" in sample_points[0] and "lat" in sample_points[0]:
                        sample_points = [(pt["lng"], pt["lat"]) for pt in sample_points]
                    elif "lon" in sample_points[0] and "lat" in sample_points[0]:
                        sample_points = [(pt["lon"], pt["lat"]) for pt in sample_points]
                    elif "x" in sample_points[0] and "y" in sample_points[0]:
                        sample_points = [(pt["x"], pt["y"]) for pt in sample_points]
                    else:
                        raise ValueError("sample_points ä¸­çš„å­—æ®µåä¸æ”¯æŒï¼Œéœ€åŒ…å« lng/lat, lon/lat æˆ– x/y")
                sample_points = np.array(sample_points)
                ax.scatter(sample_points[:, 0], sample_points[:, 1],
                           c='blue', s=10, label='é’»äº•ç‚¹', zorder=5)
            except Exception as point_err:
                print(f"âš ï¸ æ— æ³•ç»˜åˆ¶é’»äº•ç‚¹: {point_err}")

        # ç»çº¬åº¦æ ¼å¼åŒ–
        ax.xaxis.set_major_formatter(FuncFormatter(lambda val, pos: dms_formatter(val, pos, is_lat=False)))
        ax.yaxis.set_major_formatter(FuncFormatter(lambda val, pos: dms_formatter(val, pos, is_lat=True)))

        # æŒ‡å—é’ˆ
        draw_north_arrow(ax, x=0.92, y=0.92, size=0.15)

        # è®¾ç½®åæ ‡èŒƒå›´
        ax.set_xlim(102, 111)
        ax.set_ylim(27, 33)
        ax.set_aspect('equal', adjustable='box')

        # è®¾ç½®åˆ»åº¦
        xticks = np.arange(102, 112, 1)
        yticks = np.arange(27, 34, 1)
        ax.set_xticks(xticks)
        ax.set_yticks(yticks)

        # æ¨ªåæ ‡éš”ä¸€ä¸ªæ˜¾ç¤ºä¸€ä¸ªæ ‡ç­¾
        xtick_labels = [f"{x}Â°E" if i % 2 == 0 else "" for i, x in enumerate(xticks)]
        ytick_labels = [f"{y}Â°N" for y in yticks]

        ax.set_xticklabels(xtick_labels, fontsize=10)
        ax.set_yticklabels(ytick_labels, fontsize=10)

        # ä¿å­˜å›¾åƒ
        output_path = os.path.join(output_dir, filename)
        fig.savefig(output_path, format="png", bbox_inches="tight", dpi=dpi)
        plt.close(fig)
        print(f"âœ… æ’å€¼å›¾å·²ä¿å­˜åˆ°: {output_path}")
        return output_path

    except Exception as e:
        print(f"âŒ æ’å€¼å›¾ä¿å­˜å¤±è´¥: {e}")
        return None

def compute_krme_krmse(y_true, y_pred):
    y_true = np.array(y_true)
    y_pred = np.array(y_pred)
    # mean_y = np.mean(y_true)
    # krme = np.mean(y_pred - y_true) / mean_y
    # krmse = np.sqrt(np.mean((y_pred - y_true) ** 2)) / mean_y

    krme = np.mean(y_pred - y_true)  # æ–°å…¬å¼ (3)
    std_y = np.std(y_true)
    krmse = np.mean(((y_pred - y_true) ** 2) / (std_y ** 2))

    return krme, krmse


@app.post("/kriging/vector")
async def kriging_vector(request: Request):
    try:
        data = await request.json()
        features = data.get("features", [])
        print("ğŸ“¥ æ¥æ”¶åˆ°å‰ç«¯æ•°æ®ï¼Œç‚¹æ•°:", len(features))

        if len(features) < 3:
            return {"error": "è‡³å°‘éœ€è¦3ä¸ªæ•°æ®ç‚¹è¿›è¡Œæ’å€¼"}
        # è·å–æ’å€¼å‚æ•°
        params = data.get("krigingParams", {})
        kriging_method = params.get("model", "ok").lower()
        kriging_model_input = params.get("variogram_model", "spherical").lower()
        auto_optimize = params.get("autoOptimizeModel", False)
        sigma = float(params.get("smoothSigma", 0))
        property_field = params.get("property", "level")
        output_path = params.get("outputPath", "")

        # æå–æœ‰æ•ˆç‚¹
        valid_points = [
            (f["geometry"]["coordinates"][0],
             f["geometry"]["coordinates"][1],
             f["properties"].get(property_field))
            for f in features
            if f["properties"].get(property_field) is not None
        ]

        if len(valid_points) < 3:
            return {"error": f"æœ‰æ•ˆçš„ {property_field} æ•°æ®ä¸è¶³ï¼Œæ— æ³•æ’å€¼"}

        # æ‹†åˆ†ç»çº¬åº¦ä¸å€¼
        lons, lats, values = zip(*valid_points)
        lons = np.array(lons)
        lats = np.array(lats)
        values = np.array(values, dtype=float)
        coords = np.column_stack((lons, lats))

        # åæ ‡æŠ•å½±è‡³ç±³åˆ¶å¹³é¢ï¼ˆEPSG:3857ï¼‰
        transformer = Transformer.from_crs("epsg:4326", "epsg:3857", always_xy=True)
        projected_coords = np.array([transformer.transform(lon, lat) for lon, lat in coords])

        if auto_optimize:
            # åªä¼˜åŒ–å‰ç«¯ä¼ å…¥çš„æ¨¡å‹ç±»å‹çš„å‚æ•°ï¼Œä¸éå†å€™é€‰æ¨¡å‹
            best_result = optimize_single_model(kriging_model_input, projected_coords, values)
            if best_result is None:
                print("âŒ ä¼˜åŒ–å¤±è´¥ï¼Œæ— æ³•æ‹Ÿåˆæœ‰æ•ˆçš„åŠå˜å¼‚å‡½æ•°")
                return {"error": "è‡ªåŠ¨ä¼˜åŒ–å¤±è´¥ï¼Œæ— æ³•æ‹Ÿåˆæœ‰æ•ˆçš„åŠå˜å¼‚å‡½æ•°"}

            kriging_model = best_result["model"]
            nugget = max(best_result["nugget"], 0.05 * best_result["sill"])
            partial_sill = best_result["partial_sill"]
            sill = nugget + partial_sill
            nugget_ratio = nugget / sill if sill != 0 else 0
            range_ = best_result["range"]
            RSS = best_result["rss"]
            R2 = best_result["r2"]
            exp_lags = best_result["exp_lags"]
            exp_gamma = best_result["exp_gamma"]
            fit_gamma = best_result["fit_gamma"]

            variogram_plot_base64 = generate_variogram_plot_from_data(
                exp_lags, exp_gamma, fit_gamma, kriging_model,
                title_suffix=f"({kriging_method.upper()})"
            )

            print("ğŸŸ¢ è‡ªåŠ¨ä¼˜åŒ–åæ¨¡å‹å‚æ•°ï¼š")
            print(f"æ¨¡å‹: {kriging_model}")
            print(f"å—é‡‘å€¼ Nugget: {nugget:.4f}")
            print(f"åŸºå°å€¼ Sill: {sill:.4f}")
            print(f"ååŸºå° Partial Sill: {partial_sill:.4f}")
            print(f"å—é‡‘æ¯”ä¾‹ Nugget Ratio: {nugget_ratio:.4f}")
            print(f"å˜ç¨‹ Range: {range_:.4f}")
            print(f"æ®‹å·®å¹³æ–¹å’Œ RSS: {RSS:.6f}")
            print(f"å†³å®šç³»æ•° RÂ²: {R2:.4f}")


        else:

            # âœ… ç”¨æˆ·è‡ªé€‰æ¨¡å‹ï¼Œä½¿ç”¨ skgstat Variogram æ‹Ÿåˆ

            kriging_model = kriging_model_input
            V = Variogram(projected_coords, values, model=kriging_model, normalize=False, fit_method="trf",
                          fit_range=(0, 300_000))
            variogram_plot_base64 = generate_variogram_plot(V, kriging_model,
                                                            title_suffix=f"({kriging_method.upper()})")
            try:
                sill, range_, nugget = V.parameters
                if any(param <= 0 for param in [sill, range_]):
                    raise ValueError("æ‹Ÿåˆå‚æ•°å¼‚å¸¸")
            except Exception:
                sill = np.var(values)
                range_ = max(lons.max() - lons.min(), lats.max() - lats.min()) / 3
                nugget = 1.2 * sill
            partial_sill = sill - nugget
            nugget_ratio = nugget / sill if sill != 0 else 0
            exp_lags = V.bins
            exp_gamma = V.experimental
            fit_gamma = V.fitted_model(exp_lags)
            RSS = np.sum((exp_gamma - fit_gamma) ** 2)
            SS_tot = np.sum((exp_gamma - np.mean(exp_gamma)) ** 2)
            R2 = 1 - RSS / SS_tot if SS_tot != 0 else float('nan')
            print("ğŸŸ¡ æœªä¼˜åŒ–æ¨¡å‹å‚æ•°ï¼ˆä½¿ç”¨ç”¨æˆ·é€‰æ‹©æ¨¡å‹ï¼‰:")
            print(f"æ¨¡å‹: {kriging_model}")
            print(f"å—é‡‘å€¼ Nugget: {nugget:.4f}")
            print(f"åŸºå°å€¼ Sill: {sill:.4f}")
            print(f"ååŸºå° Partial Sill: {partial_sill:.4f}")
            print(f"å—é‡‘æ¯”ä¾‹ Nugget Ratio: {nugget_ratio:.4f}")
            print(f"å˜ç¨‹ Range: {range_:.4f}")
            print(f"æ®‹å·®å¹³æ–¹å’Œ RSS: {RSS:.6f}")
            print(f"å†³å®šç³»æ•° RÂ²: {R2:.4f}")
        if basin_union:
            minx, miny, maxx, maxy = basin_union.bounds
        else:
            minx, maxx = lons.min(), lons.max()
            miny, maxy = lats.min(), lats.max()

        expand_x = (maxx - minx) * 0.5
        expand_y = (maxy - miny) * 0.5
        minx -= expand_x
        maxx += expand_x
        miny -= expand_y
        maxy += expand_y

        grid_res = 400
        grid_lon = np.linspace(minx, maxx, grid_res)
        grid_lat = np.linspace(miny, maxy, grid_res)
        grid_x, grid_y = np.meshgrid(grid_lon, grid_lat)

        # âœ… æ ¡éªŒæ¨¡å‹åˆæ³•æ€§
        valid_models_ok = {"spherical", "exponential", "gaussian", "linear", "circular"}
        valid_models_uk = {"spherical", "exponential", "gaussian", "linear"}

        if kriging_method == "ok":
            if kriging_model not in valid_models_ok:
                return {"error": f"æ™®é€šå…‹é‡Œé‡‘æ³•ä¸æ”¯æŒæ¨¡å‹ '{kriging_model}'"}
        elif kriging_method == "uk":
            if kriging_model not in valid_models_uk:
                return {"error": f"æ³›å…‹é‡Œé‡‘æ³•ä¸æ”¯æŒæ¨¡å‹ '{kriging_model}'"}
        else:
            return {"error": f"æœªçŸ¥çš„å…‹é‡Œé‡‘æ–¹æ³• '{kriging_method}'"}

        if kriging_method == "uk":
            drift_type = (params.get("drift") or "linear").lower()
            if drift_type == "linear":
                drift_terms = ["regional_linear"]
            elif drift_type == "quadratic":
                drift_terms = ["regional_quadratic"]
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ³›å…‹é‡Œé‡‘æ¼‚ç§»ç±»å‹: {drift_type}")

            # âœ… è¾“å‡ºä½¿ç”¨çš„é…ç½®
            print(f"âœ… ä½¿ç”¨æ–¹æ³•: Universal Krigingï¼ˆæ³›å…‹é‡Œé‡‘ï¼‰")
            print(f"âœ… æ¼‚ç§»ç±»å‹: {drift_type}")
            print(f"âœ… åŠå˜å¼‚æ¨¡å‹: {kriging_model}")

            import io, sys, re
            buffer = io.StringIO()
            sys_stdout = sys.stdout
            sys.stdout = buffer  # é‡å®šå‘ stdout æ•è· pykrige è¾“å‡º

            try:
                kriging = UniversalKriging(
                    lons, lats, values,
                    variogram_model=kriging_model,
                    drift_terms=drift_terms,
                    verbose=True,
                    enable_plotting=False
                )
                z_raw, ss = kriging.execute("grid", grid_lon, grid_lat)

                # äº¤å‰éªŒè¯è®¡ç®—RSSå’ŒR2
                # RSS, R2 = cross_validation_uk(lons, lats, values, kriging_model, drift_terms)

                # KæŠ˜äº¤å‰éªŒè¯
                RSS, R2, KRME, KRMSE = kfold_uk_cross_validation(
                    lons, lats, values, kriging_model, drift_terms, 5
                )
                print(f"æ³›å…‹é‡Œé‡‘äº¤å‰éªŒè¯æ®‹å·®å¹³æ–¹å’Œ RSS: {RSS:.4f}")
                print(f"æ³›å…‹é‡Œé‡‘äº¤å‰éªŒè¯å†³å®šç³»æ•° RÂ²: {R2:.4f}")
            finally:
                sys.stdout = sys_stdout  # æ¢å¤ stdout

            # æå– pykrige è¾“å‡ºä¸­çš„æ‹Ÿåˆå‚æ•°
            output = buffer.getvalue()
            print(output)

            nugget_match = re.search(r"Nugget:\s*([0-9.eE+-]+)", output)
            sill_match = re.search(r"Full Sill:\s*([0-9.eE+-]+)", output)
            psill_match = re.search(r"Partial Sill:\s*([0-9.eE+-]+)", output)
            range_match = re.search(r"Range:\s*([0-9.eE+-]+)", output)

            if all([nugget_match, sill_match, psill_match, range_match]):
                nugget_fitted = float(nugget_match.group(1))
                sill_fitted = float(sill_match.group(1))
                psill_fitted = float(psill_match.group(1))
                range_fitted = float(range_match.group(1))
                nugget_ratio = nugget_fitted / sill_fitted if sill_fitted else 0

                print("ğŸ“Š æ³›å…‹é‡Œé‡‘å®é™…ä½¿ç”¨æ¨¡å‹å‚æ•°ï¼š")
                print(f"å—é‡‘å€¼ Nugget: {nugget_fitted:.4f}")
                print(f"åŸºå°å€¼ Sill: {sill_fitted:.4f}")
                print(f"ååŸºå° Partial Sill: {psill_fitted:.4f}")
                print(f"å—é‡‘æ¯”ä¾‹ Nugget Ratio: {nugget_ratio:.4f}")
                print(f"å˜ç¨‹ Range (m): {range_fitted:.4f}")
            else:
                print("âš ï¸ æœªèƒ½ä» pykrige è¾“å‡ºä¸­æå–æ¨¡å‹å‚æ•°")

        elif kriging_method == "ok":
            print(f"âœ… ä½¿ç”¨æ–¹æ³•: Ordinary Krigingï¼ˆæ™®é€šå…‹é‡Œé‡‘ï¼‰")
            print(f"âœ… åŠå˜å¼‚æ¨¡å‹: {kriging_model}")
            print(f"âœ… ä½¿ç”¨å‚æ•°: sill={sill}, range={range_}, nugget={nugget}")

            kriging = OrdinaryKriging(
                lons, lats, values,
                variogram_model=kriging_model,
                variogram_parameters={"sill": sill, "range": range_, "nugget": nugget},
                verbose=True,
                enable_plotting=False
            )
            z_raw, ss = kriging.execute("grid", grid_lon, grid_lat, backend="vectorized")
            # è°ƒç”¨ç•™ä¸€äº¤å‰éªŒè¯å‡½æ•°
            try:
                RSS, R2, KRME, KRMSE, best_nugget = loo_cross_validation_ok(
                    lons, lats, values, sill, nugget, range_, kriging_model, auto_optimize_nugget=True
                )
                print(f"æ™®é€šå…‹é‡Œé‡‘ä¼˜åŒ–å nugget = {best_nugget:.4f}")
                print(f"æ™®é€šå…‹é‡Œé‡‘ï¼šRSS = {RSS:.4f}, R2 = {R2:.4f}, KRME = {KRME:.4f}, KRMSE = {KRMSE:.4f}")
            except Exception as e:
                print(f"âš ï¸ å¿«é€Ÿäº¤å‰éªŒè¯å¤±è´¥: {e}")
                RSS, R2 = None, None

        else:
            return {"error": f"æœªçŸ¥çš„å…‹é‡Œé‡‘æ–¹æ³• '{kriging_method}'"}

        # å¹³æ»‘+è£å‰ª
        z_filtered = gaussian_filter(z_raw, sigma=sigma) if sigma > 0 else z_raw
        z = mask_outside_boundary(grid_x, grid_y, z_filtered, basin_union)

        # æ£€æŸ¥æ’å€¼æœ‰æ•ˆæ€§
        if np.isclose(np.nanmin(z), np.nanmax(z)):
            return {"error": "æ’å€¼ç»“æœæ— å·®å¼‚", "value": float(np.nanmin(z))}

        z_flat = z[~np.isnan(z)]
        if len(z_flat) < 11:
            return {"error": "æœ‰æ•ˆåŒºåŸŸ z å€¼ä¸è¶³ï¼Œæ— æ³•ä½¿ç”¨ Jenks åˆ†çº§"}

        # ç”Ÿæˆç­‰å€¼çº¿
        contour_levels = jenkspy.jenks_breaks(z_flat, 11)
        contour_levels = np.unique(contour_levels)
        if len(contour_levels) < 2:
            return {"error": "ç­‰å€¼çº¿çº§åˆ«ä¸è¶³ï¼Œæ— æ³•ç»˜åˆ¶ç­‰å€¼çº¿"}

        # ä» features ä¸­æå–åæ ‡å…ƒç»„åˆ—è¡¨ (lng, lat)
        sample_points = [
            (f["geometry"]["coordinates"][0], f["geometry"]["coordinates"][1])
            for f in features
            if f.get("geometry") and f["geometry"]["type"].lower() == "point"
        ]
        contour_img_path = save_kriging_contour_plot(grid_x, grid_y, z, contour_levels, sample_points)
        fig, ax = plt.subplots(figsize=(8, 6), dpi=300)
        cs = ax.contourf(grid_x, grid_y, z, levels=contour_levels, cmap=palettable.colorbrewer.diverging.RdYlBu_11_r.mpl_colormap)
        plt.close(fig)

        level_polygons = []
        for i in range(len(contour_levels) - 1):
            polys = []
            if i >= len(cs.allsegs):
                level_polygons.append(None)
                continue
            for seg in cs.allsegs[i]:
                if len(seg) < 3:
                    continue
                if not np.array_equal(seg[0], seg[-1]):
                    seg = np.vstack([seg, seg[0]])
                poly = ShapelyPolygon(seg)
                if poly.is_valid and poly.area > 1e-10:
                    polys.append(poly)
            if polys:
                level_polygons.append(unary_union(polys))
            else:
                level_polygons.append(None)

        features_result = []
        valid_contour_levels = []
        for i in range(len(level_polygons)):
            current_poly = level_polygons[i]
            if current_poly is None or current_poly.is_empty:
                continue
            next_poly = level_polygons[i + 1] if i + 1 < len(level_polygons) else None
            band = current_poly
            if next_poly and not next_poly.is_empty:
                band = current_poly.difference(next_poly)
            if basin_union:
                band = band.intersection(basin_union)
            if band.is_empty:
                continue
            geoms = extract_polygons(band)
            for geom in geoms:
                if not geom.is_valid or geom.area < 1e-6:
                    continue
                coords = list(geom.exterior.coords)
                coords_rounded = [(round(x, 6), round(y, 6)) for x, y in coords]
                gj_poly = GeoJSONPolygon([coords_rounded])
                features_result.append(Feature(geometry=gj_poly, properties={
                    "value": float(contour_levels[i]),
                    "min_value": float(contour_levels[i]),
                    "max_value": float(contour_levels[i + 1])
                }))
            valid_contour_levels.append(contour_levels[i])

        # ç”ŸæˆshapefileåŠzipï¼Œå¹¶è¿”å›ä¸‹è½½åœ°å€
        zip_download_url = None
        if output_path:
            try:
                output_dir = os.path.dirname(output_path)
                if output_dir and not os.path.exists(output_dir):
                    os.makedirs(output_dir, exist_ok=True)

                save_features_to_shapefile(features_result, output_path)
                zip_path = zip_shapefile(output_path)
                zip_filename = os.path.basename(zip_path)
                zip_download_url = f"/download/{zip_filename}"
                print(f"âœ… Shapefile åŠ zip å·²ä¿å­˜ï¼Œä¸‹è½½åœ°å€: {zip_download_url}")
            except Exception as e:
                print(f"âŒ ä¿å­˜ Shapefile æˆ–å‹ç¼© zip å¤±è´¥: {e}")

        return {
            "type": "FeatureCollection",
            "features": features_result,
            "properties": {
                "contour_levels": valid_contour_levels,
                "contour_image_path": contour_img_path,
                "download_url": zip_download_url,
                "variogram_plot_base64": variogram_plot_base64,
                "used_kriging_model": kriging_model,
                "nugget": nugget,
                "sill": sill,
                "partial_sill": partial_sill,
                "nugget_ratio": nugget_ratio,
                "range": range_,
                "fit_rss": best_result["rss"] if auto_optimize else None
            }
        }

    except Exception as e:
        tb = traceback.format_exc()
        print("âŒ Kriging error:", e)
        print(tb)
        return {"error": str(e), "traceback": tb, "details": "æ’å€¼è¿‡ç¨‹å‘ç”Ÿé”™è¯¯"}


@app.get("/download/{filename}")
def download_file(filename: str):
    file_path = os.path.join("output", filename)
    if os.path.exists(file_path) and os.path.isfile(file_path):
        return FileResponse(file_path, media_type="application/zip", filename=filename)
    else:
        raise HTTPException(status_code=404, detail="æ–‡ä»¶æœªæ‰¾åˆ°")



import uvicorn
if __name__ == "__main__":
    uvicorn.run("main:app", host="127.0.0.1", port=8000, reload=True)



# åˆ¤æ–­æ˜¯å¦æ­£æ€åˆ†å¸ƒ
# import pandas as pd
# import matplotlib.pyplot as plt
# from scipy.stats import norm
# import numpy as np
# import matplotlib
# matplotlib.use('TkAgg')
#
# # === 1. è¯»å– Excel æ–‡ä»¶ ===
# # æ›¿æ¢ä¸ºä½ çš„æ–‡ä»¶è·¯å¾„å’Œ Sheet åç§°
# file_path = 'stratum.xlsx'
# sheet_name = 'Sheet1'
# column_name = 'start_depth'
#
# # è¯»å–æ•°æ®
# df = pd.read_excel(file_path, sheet_name=sheet_name)
#
# # å»é™¤ç¼ºå¤±å€¼ï¼Œä»…ä¿ç•™æœ‰æ•ˆæ•°å€¼
# data = df[column_name].dropna().values
#
# # === 2. ç»˜åˆ¶ç›´æ–¹å›¾ ===
# plt.figure(figsize=(8, 6))
# plt.hist(data, bins=20, color='skyblue', edgecolor='black', alpha=0.7, density=True)
#
# # æ­£æ€åˆ†å¸ƒæ‹Ÿåˆæ›²çº¿
# mu, std = norm.fit(data)
# xmin, xmax = plt.xlim()
# x = np.linspace(xmin, xmax, 100)
# p = norm.pdf(x, mu, std)
# plt.plot(x, p, 'r--', linewidth=2, label=f'Normal fit: Î¼={mu:.2f}, Ïƒ={std:.2f}')
#
# # æ ‡æ³¨å›¾ä¾‹å’Œæ ‡é¢˜
# plt.title(f"{column_name} çš„ç›´æ–¹å›¾ï¼ˆå«æ­£æ€æ‹Ÿåˆï¼‰", fontsize=14)
# plt.xlabel("å€¼")
# plt.ylabel("é¢‘ç‡å¯†åº¦")
# plt.legend()
# plt.grid(True)
# plt.tight_layout()
# plt.show()
